{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e289c7-14f5-4af9-b60c-906b15dc315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44001995-47a5-4bac-8f40-4a315335d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_historic_data(ticker):\n",
    "    \"\"\"It saves the data from 2006 to current date\n",
    "    in csv file in current directory\"\"\"\n",
    "    \n",
    "    from datetime import datetime\n",
    "    current_date = datetime.now()\n",
    "    current_date = current_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    data = yf.download(ticker, start=\"2000-01-01\", end=\"2024-12-30\")\n",
    "    data.reset_index(inplace=True)\n",
    "\n",
    "    data = data.rename(columns={\n",
    "        'Date': 'date',\n",
    "        'Open': 'open',\n",
    "        'High': 'high',\n",
    "        'Low': 'low',\n",
    "        'Close': 'close',\n",
    "        'Volume': 'volume'\n",
    "    })\n",
    "    data['date']=pd.to_datetime(data['date'])\n",
    "    \n",
    "\n",
    "    csv_file = f'raw data/{ticker}_data.csv'\n",
    "    data.to_csv(csv_file, index=False)  # index=False to exclude the default pandas index\n",
    "    del_sec_row(csv_file)\n",
    "    print(f\"TCS data saved to {csv_file}\")\n",
    "   \n",
    "\n",
    "def del_sec_row(file_path):\n",
    "    import csv\n",
    "    \n",
    "    # Read and write in one go, skipping the second row\n",
    "    with open(file_path, mode=\"r\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        rows = list(csv.reader(file))  # Load all rows\n",
    "    \n",
    "    # Remove the second row\n",
    "    if len(rows) > 1:\n",
    "        rows.pop(1)\n",
    "    \n",
    "    # Save the updated rows back to the file\n",
    "    with open(file_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        csv.writer(file).writerows(rows)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "437ce969-d671-4d46-b29e-8a1c9eeba531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCS data saved to raw data/MRF.NS_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "download_historic_data(\"MRF.NS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53d83a43-bef2-4a34-a610-bcf8602303f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def technical_generator(ticker):\n",
    "    file_path=f'raw data/{ticker}_data.csv'\n",
    "    data=pd.read_csv(file_path)\n",
    "    df=data\n",
    "\n",
    "\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['year'] = data['date'].dt.year\n",
    "    data['month'] = data['date'].dt.month\n",
    "    data['day'] = data['date'].dt.day\n",
    "    data['dayofweek'] = data['date'].dt.dayofweek\n",
    "    data['quarter'] = data['date'].dt.quarter\n",
    "    data['dayofyear'] = data['date'].dt.dayofyear\n",
    "\n",
    "\n",
    "    # Add Simple Moving Averages (SMA)\n",
    "    data['SMA_5'] = ta.sma(data['close'], length=5)\n",
    "    data['SMA_8'] = ta.sma(data['close'], length=8)\n",
    "    df['SMA_13'] = ta.sma(df['close'], length=13)\n",
    "    df['SMA_21'] = ta.sma(df['close'], length=21)\n",
    "    df['SMA_50'] = ta.sma(df['close'], length=50)\n",
    "   \n",
    "    \n",
    "    # Add Exponential Moving Averages (EMA)\n",
    "    data['EMA_5'] = ta.ema(data['close'], length=5)\n",
    "    data['EMA_8'] = ta.ema(data['close'], length=8)\n",
    "    data['EMA_13'] = ta.ema(data['close'], length=13)\n",
    "    df['EMA_21'] = ta.ema(df['close'], length=21)\n",
    "    df['EMA_50'] = ta.ema(df['close'], length=50)\n",
    " \n",
    "    \n",
    "    # Add Stochastic Oscillator (%K and %D)\n",
    "    stoch = ta.stoch(df['high'], df['low'], df['close'], k=14, d=3)\n",
    "    df['Stoch_%K'] = stoch['STOCHk_14_3_3']\n",
    "    df['Stoch_%D'] = stoch['STOCHd_14_3_3']\n",
    "    \n",
    "    # Add Average Directional Index (ADX)\n",
    "    df['ADX'] = ta.adx(df['high'], df['low'], df['close'], length=14)['ADX_14']\n",
    "\n",
    "    # Add Lag Features\n",
    "    df['Close_lag1'] = df['close'].shift(1)\n",
    "    data['close_lag2'] = data['close'].shift(2)\n",
    "\n",
    "    \n",
    "    # Add Daily Returns and Log Returns\n",
    "    df['Daily_Return'] = df['close'].pct_change()\n",
    "    df['Log_Return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # date is as index    \n",
    "    data.set_index('date', inplace=True)\n",
    "    \n",
    "\n",
    "    # Assuming your data is loaded in the DataFrame 'data'\n",
    "    # Ensure the date column is in datetime format and set it as index\n",
    "    \n",
    "    \n",
    "    # Assuming 'data' is your DataFrame and 'date' is the index\n",
    "    # Ensure the 'close' column is properly formatted as numeric\n",
    "    data['close'] = pd.to_numeric(data['close'], errors='coerce')\n",
    "    \n",
    "    # Fill any NaN values that may appear (using .ffill)\n",
    "    data['close'] = data['close'].ffill()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Calculate MACD using pandas_ta\n",
    "    macd_result = ta.macd(data['close'], fast=12, slow=26, signal=9)\n",
    "    \n",
    "    # Add MACD components to the data\n",
    "    data['MACD'] = macd_result['MACD_12_26_9']\n",
    "    data['MACD_signal'] = macd_result['MACDs_12_26_9']\n",
    "    data['MACD_hist'] = macd_result['MACDh_12_26_9']\n",
    "    \n",
    "    # 2. Calculate RSI (Relative Strength Index)\n",
    "    data['RSI'] = ta.rsi(data['close'], length=14)\n",
    "    \n",
    "    # Step 2: Recalculate VWAP after setting 'date' as the index\n",
    "    data['VWAP'] = ta.vwap(high=data['high'], low=data['low'], close=data['close'], volume=data['volume'])\n",
    "    \n",
    "    # Calculate Bollinger Bands (returns a DataFrame, not individual series)\n",
    "    bbands = ta.bbands(data['close'], length=20, std=2)\n",
    "    \n",
    "    \n",
    "    # Extract the individual bands from the result\n",
    "    data['BB_upper'] = bbands['BBL_20_2.0']\n",
    "    data['BB_middle'] = bbands['BBM_20_2.0']\n",
    "    data['BB_lower'] = bbands['BBU_20_2.0']\n",
    "\n",
    "    \n",
    "    # 4. Calculate On-Balance Volume (OBV)\n",
    "    data['OBV'] = ta.obv(data['close'], data['volume'])\n",
    "\n",
    "    \n",
    "    # Default parameters for AF (Acceleration Factor) are 0.02 and maximum AF is 0.2\n",
    "    # Calculate Parabolic SAR\n",
    "    # pandas_ta.psar returns multiple columns: `PSARl_0.02_0.2`, `PSARs_0.02_0.2`, and `PSAR_0.02_0.2`\n",
    "    psar = ta.psar(data['high'], data['low'], data['close'], step=0.02, max_step=0.2)\n",
    "\n",
    "    \n",
    "    # Combine PSARl and PSARs into a single column\n",
    "    data['PSAR'] = psar['PSARl_0.02_0.2'].combine_first(psar['PSARs_0.02_0.2'])\n",
    "\n",
    "\n",
    "    # 5. Calculate ATR (Average True Range)\n",
    "    data['ATR'] = ta.atr(data['high'], data['low'], data['close'], length=14)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # Calculate Ichimoku Cloud\n",
    "    ichimoku = ta.ichimoku(data['high'], data['low'], data['close'], window1=9, window2=26, window3=52)\n",
    "    # Extract Ichimoku components\n",
    "    data['Tenkan-sen'] = ichimoku[0]['ITS_9']  # Conversion Line\n",
    "    data['Kijun-sen'] = ichimoku[0]['IKS_26']  # Base Line\n",
    "    data['Chikou Span'] = ichimoku[0]['ICS_26']  # Lagging Span\n",
    "\n",
    "        \n",
    "\n",
    "    # Calculate CCI Commodity Channel Index (CCI) \n",
    "    data['CCI'] = ta.cci(data['high'], data['low'], data['close'], length=20)\n",
    "\n",
    "\n",
    "\n",
    "    # Reset index to make 'date' a regular column\n",
    "    data = data.reset_index()\n",
    "\n",
    "\n",
    "    # data=data_reset.dropna() \n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    new_file=f'technical indicators/{ticker}_indicators.csv'\n",
    "    data.to_csv(new_file, index=False)\n",
    "    print(f\"TCS data saved to {new_file}\")\n",
    "    return data\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4276290f-f11b-4fd2-a74d-d49b4732e28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCS data saved to technical indicators/TCS.NS_indicators.csv\n"
     ]
    }
   ],
   "source": [
    "data=technical_generator(\"TCS.NS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "637026c4-fdf5-46af-ba42-db658680bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "\n",
    "def get_directory(base_dir, data_type):\n",
    "    \"\"\"Returns the correct directory path for storing data.\"\"\"\n",
    "    if data_type not in ['train', 'test']:\n",
    "        raise ValueError(\"Invalid data_type. Choose 'train' or 'test'\")\n",
    "    \n",
    "    raw_data_dir = os.path.join(base_dir, data_type, 'raw_data')\n",
    "    tech_data_dir = os.path.join(base_dir, data_type, 'technical_indicators')\n",
    "    os.makedirs(raw_data_dir, exist_ok=True)\n",
    "    os.makedirs(tech_data_dir, exist_ok=True)\n",
    "    \n",
    "    return raw_data_dir, tech_data_dir\n",
    "\n",
    "def download_historic_data(ticker, data_type='train', base_dir='data'):\n",
    "    \"\"\"Downloads historical stock data and saves it to the appropriate directory.\"\"\"\n",
    "    raw_data_dir, _ = get_directory(base_dir, data_type)\n",
    "    csv_file = os.path.join(raw_data_dir, f'{ticker}_data.csv')\n",
    "    \n",
    "    data = yf.download(ticker, start=\"2024-12-01\", end=\"2025-02-01\")\n",
    "    data.reset_index(inplace=True)\n",
    "    \n",
    "    data = data.rename(columns={'Date': 'date', 'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close', 'Volume': 'volume'})\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    \n",
    "    data.to_csv(csv_file, index=False)\n",
    "    del_second_row(csv_file)\n",
    "    print(f\"Data saved to {csv_file}\")\n",
    "\n",
    "def del_second_row(file_path):\n",
    "    \"\"\"Removes the second row from a CSV file.\"\"\"\n",
    "    import csv\n",
    "    with open(file_path, \"r\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        rows = list(csv.reader(file))\n",
    "    if len(rows) > 1:\n",
    "        rows.pop(1)\n",
    "    with open(file_path, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        csv.writer(file).writerows(rows)\n",
    "\n",
    "def generate_technical_indicators(ticker, data_type='train', base_dir='data'):\n",
    "    \"\"\"Loads raw stock data, computes technical indicators, and saves it.\"\"\"\n",
    "    raw_data_dir, tech_data_dir = get_directory(base_dir, data_type)\n",
    "    \n",
    "    file_path = os.path.join(raw_data_dir, f'{ticker}_data.csv')\n",
    "    new_file = os.path.join(tech_data_dir, f'{ticker}_indicators.csv')\n",
    "\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['year'] = data['date'].dt.year\n",
    "    data['month'] = data['date'].dt.month\n",
    "    data['day'] = data['date'].dt.day\n",
    "    data['dayofweek'] = data['date'].dt.dayofweek\n",
    "    data['quarter'] = data['date'].dt.quarter\n",
    "    data['dayofyear'] = data['date'].dt.dayofyear\n",
    "\n",
    "    # Add Simple Moving Averages (SMA)\n",
    "    data['SMA_5'] = ta.sma(data['close'], length=5)\n",
    "    data['SMA_8'] = ta.sma(data['close'], length=8)\n",
    "    data['SMA_13'] = ta.sma(data['close'], length=13)\n",
    "    data['SMA_21'] = ta.sma(data['close'], length=21)\n",
    "    data['SMA_50'] = ta.sma(data['close'], length=50)\n",
    "   \n",
    "    # Add Exponential Moving Averages (EMA)\n",
    "    data['EMA_5'] = ta.ema(data['close'], length=5)\n",
    "    data['EMA_8'] = ta.ema(data['close'], length=8)\n",
    "    data['EMA_13'] = ta.ema(data['close'], length=13)\n",
    "    data['EMA_21'] = ta.ema(data['close'], length=21)\n",
    "    data['EMA_50'] = ta.ema(data['close'], length=50)\n",
    " \n",
    "    # Add Stochastic Oscillator (%K and %D)\n",
    "    stoch = ta.stoch(data['high'], data['low'], data['close'], k=14, d=3)\n",
    "    data['Stoch_%K'] = stoch['STOCHk_14_3_3']\n",
    "    data['Stoch_%D'] = stoch['STOCHd_14_3_3']\n",
    "    \n",
    "    # Add Average Directional Index (ADX)\n",
    "    data['ADX'] = ta.adx(data['high'], data['low'], data['close'], length=14)['ADX_14']\n",
    "\n",
    "    # Add Lag Features\n",
    "    data['Close_lag1'] = data['close'].shift(1)\n",
    "    data['close_lag2'] = data['close'].shift(2)\n",
    "    \n",
    "    # Add Daily Returns\n",
    "    data['Daily_Return'] = data['close'].pct_change()\n",
    "\n",
    "    # date is as index    \n",
    "    data.set_index('date', inplace=True)\n",
    "     \n",
    "    data['close'] = pd.to_numeric(data['close'], errors='coerce')  # Convert to float\n",
    "    data['close'].fillna(method='ffill', inplace=True)  # Fill missing values\n",
    "\n",
    "    \n",
    "    # Calculate MACD using pandas_ta\n",
    "    macd_result = ta.macd(data['close'], fast=12, slow=26, signal=9)\n",
    "    \n",
    "    # Add MACD components to the data\n",
    "    data['MACD'] = macd_result['MACD_12_26_9']\n",
    "    data['MACD_signal'] = macd_result['MACDs_12_26_9']\n",
    "    data['MACD_hist'] = macd_result['MACDh_12_26_9']\n",
    "    \n",
    "    # 2. Calculate RSI (Relative Strength Index)\n",
    "    data['RSI'] = ta.rsi(data['close'], length=14)\n",
    "    \n",
    "    # Step 2: Recalculate VWAP after setting 'date' as the index\n",
    "    data['VWAP'] = ta.vwap(high=data['high'], low=data['low'], close=data['close'], volume=data['volume'])\n",
    "    \n",
    "    # # Calculate Bollinger Bands (returns a DataFrame, not individual series)\n",
    "    # bbands = ta.bbands(data['close'], length=20, std=2)\n",
    "     \n",
    "    # # Extract the individual bands from the result\n",
    "    # data['BB_upper'] = bbands['BBL_20_2.0']\n",
    "    # data['BB_middle'] = bbands['BBM_20_2.0']\n",
    "    # data['BB_lower'] = bbands['BBU_20_2.0']\n",
    "    data['BB_upper'], data['BB_middle'], data['BB_lower'] = ta.bbands(data['close'], length=20)[['BBU_20_2.0', 'BBM_20_2.0', 'BBL_20_2.0']].T.values\n",
    "\n",
    "    # 4. Calculate On-Balance Volume (OBV)\n",
    "    data['OBV'] = ta.obv(data['close'], data['volume'])\n",
    "\n",
    "    # Default parameters for AF (Acceleration Factor) are 0.02 and maximum AF is 0.2\n",
    "    # Calculate Parabolic SAR\n",
    "    # pandas_ta.psar returns multiple columns: `PSARl_0.02_0.2`, `PSARs_0.02_0.2`, and `PSAR_0.02_0.2`\n",
    "    psar = ta.psar(data['high'], data['low'], data['close'], step=0.02, max_step=0.2)\n",
    "\n",
    "    # Combine PSARl and PSARs into a single column\n",
    "    data['PSAR'] = psar['PSARl_0.02_0.2'].combine_first(psar['PSARs_0.02_0.2'])\n",
    "\n",
    "    # 5. Calculate ATR (Average True Range)\n",
    "    data['ATR'] = ta.atr(data['high'], data['low'], data['close'], length=14)\n",
    "\n",
    "    # Calculate Ichimoku Cloud\n",
    "    ichimoku = ta.ichimoku(data['high'], data['low'], data['close'], window1=9, window2=26, window3=52)\n",
    "    # Extract Ichimoku components\n",
    "    data['Tenkan-sen'] = ichimoku[0]['ITS_9']  # Conversion Line\n",
    "    data['Kijun-sen'] = ichimoku[0]['IKS_26']  # Base Line\n",
    "    data['Chikou Span'] = ichimoku[0]['ICS_26']  # Lagging Span\n",
    "\n",
    "    # Calculate CCI Commodity Channel Index (CCI) \n",
    "    data['CCI'] = ta.cci(data['high'], data['low'], data['close'], length=20)\n",
    "\n",
    "    # Reset index to make 'date' a regular column\n",
    "    data = data.reset_index()\n",
    "\n",
    "    data.to_csv(new_file, index=False)\n",
    "    print(f\"Technical indicators saved to {new_file}\")\n",
    "    # return data\n",
    "\n",
    "# Example Usage:\n",
    "# download_historic_data('AAPL', data_type='test')\n",
    "# generate_technical_indicators('AAPL', data_type='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7847e3c5-cde0-40c6-9d0a-5d1944feaa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def git_commit():\n",
    "    import os\n",
    "        # Push changes using git\n",
    "    repo_dir = os.getcwd() \n",
    "    os.system(f\"cd {repo_dir} && git add .\")\n",
    "    os.system(f'cd {repo_dir} && git commit -m \"Commited via Python\"')\n",
    "    os.system(f\"cd {repo_dir} && git push origin main\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ee1f6fb-f4b7-4cbb-8c33-c7afa38ae196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\R A N J I T H\\AppData\\Local\\Temp\\ipykernel_10312\\2273367588.py:94: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['close'].fillna(method='ffill', inplace=True)  # Fill missing values\n",
      "C:\\Users\\R A N J I T H\\AppData\\Local\\Temp\\ipykernel_10312\\2273367588.py:94: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data['close'].fillna(method='ffill', inplace=True)  # Fill missing values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data\\test\\raw_data\\TCS.NS_data.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m download_historic_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTCS.NS\u001b[39m\u001b[38;5;124m'\u001b[39m, data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m generate_technical_indicators(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTCS.NS\u001b[39m\u001b[38;5;124m'\u001b[39m, data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[28], line 137\u001b[0m, in \u001b[0;36mgenerate_technical_indicators\u001b[1;34m(ticker, data_type, base_dir)\u001b[0m\n\u001b[0;32m    135\u001b[0m ichimoku \u001b[38;5;241m=\u001b[39m ta\u001b[38;5;241m.\u001b[39michimoku(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m], window1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, window2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m26\u001b[39m, window3\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m52\u001b[39m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Extract Ichimoku components\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTenkan-sen\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ichimoku[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mITS_9\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Conversion Line\u001b[39;00m\n\u001b[0;32m    138\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKijun-sen\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ichimoku[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIKS_26\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Base Line\u001b[39;00m\n\u001b[0;32m    139\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChikou Span\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ichimoku[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mICS_26\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Lagging Span\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "download_historic_data('TCS.NS', data_type='test')\n",
    "generate_technical_indicators('TCS.NS', data_type='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a7ac5d-cb86-426e-8061-8f490d79a0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
