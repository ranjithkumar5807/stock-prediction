{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e289c7-14f5-4af9-b60c-906b15dc315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44001995-47a5-4bac-8f40-4a315335d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_historic_data(ticker):\n",
    "    \"\"\"It saves the data from 2006 to current date\n",
    "    in csv file in current directory\"\"\"\n",
    "    \n",
    "    from datetime import datetime\n",
    "    current_date = datetime.now()\n",
    "    current_date = current_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    data = yf.download(ticker, start=\"2000-01-01\", end=\"2024-12-30\")\n",
    "    data.reset_index(inplace=True)\n",
    "\n",
    "    data = data.rename(columns={\n",
    "        'Date': 'date',\n",
    "        'Open': 'open',\n",
    "        'High': 'high',\n",
    "        'Low': 'low',\n",
    "        'Close': 'close',\n",
    "        'Volume': 'volume'\n",
    "    })\n",
    "    data['date']=pd.to_datetime(data['date'])\n",
    "    \n",
    "\n",
    "    csv_file = f'raw data/{ticker}_data.csv'\n",
    "    data.to_csv(csv_file, index=False)  # index=False to exclude the default pandas index\n",
    "    del_sec_row(csv_file)\n",
    "    print(f\"TCS data saved to {csv_file}\")\n",
    "   \n",
    "\n",
    "def del_sec_row(file_path):\n",
    "    import csv\n",
    "    \n",
    "    # Read and write in one go, skipping the second row\n",
    "    with open(file_path, mode=\"r\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        rows = list(csv.reader(file))  # Load all rows\n",
    "    \n",
    "    # Remove the second row\n",
    "    if len(rows) > 1:\n",
    "        rows.pop(1)\n",
    "    \n",
    "    # Save the updated rows back to the file\n",
    "    with open(file_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        csv.writer(file).writerows(rows)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "437ce969-d671-4d46-b29e-8a1c9eeba531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCS data saved to raw data/MRF.NS_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "download_historic_data(\"MRF.NS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53d83a43-bef2-4a34-a610-bcf8602303f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def technical_generator(ticker):\n",
    "    file_path=f'raw data/{ticker}_data.csv'\n",
    "    data=pd.read_csv(file_path)\n",
    "    df=data\n",
    "\n",
    "\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['year'] = data['date'].dt.year\n",
    "    data['month'] = data['date'].dt.month\n",
    "    data['day'] = data['date'].dt.day\n",
    "    data['dayofweek'] = data['date'].dt.dayofweek\n",
    "    data['quarter'] = data['date'].dt.quarter\n",
    "    data['dayofyear'] = data['date'].dt.dayofyear\n",
    "\n",
    "\n",
    "    # Add Simple Moving Averages (SMA)\n",
    "    data['SMA_5'] = ta.sma(data['close'], length=5)\n",
    "    data['SMA_8'] = ta.sma(data['close'], length=8)\n",
    "    df['SMA_13'] = ta.sma(df['close'], length=13)\n",
    "    df['SMA_21'] = ta.sma(df['close'], length=21)\n",
    "    df['SMA_50'] = ta.sma(df['close'], length=50)\n",
    "   \n",
    "    \n",
    "    # Add Exponential Moving Averages (EMA)\n",
    "    data['EMA_5'] = ta.ema(data['close'], length=5)\n",
    "    data['EMA_8'] = ta.ema(data['close'], length=8)\n",
    "    data['EMA_13'] = ta.ema(data['close'], length=13)\n",
    "    df['EMA_21'] = ta.ema(df['close'], length=21)\n",
    "    df['EMA_50'] = ta.ema(df['close'], length=50)\n",
    " \n",
    "    \n",
    "    # Add Stochastic Oscillator (%K and %D)\n",
    "    stoch = ta.stoch(df['high'], df['low'], df['close'], k=14, d=3)\n",
    "    df['Stoch_%K'] = stoch['STOCHk_14_3_3']\n",
    "    df['Stoch_%D'] = stoch['STOCHd_14_3_3']\n",
    "    \n",
    "    # Add Average Directional Index (ADX)\n",
    "    df['ADX'] = ta.adx(df['high'], df['low'], df['close'], length=14)['ADX_14']\n",
    "\n",
    "    # Add Lag Features\n",
    "    df['Close_lag1'] = df['close'].shift(1)\n",
    "    data['close_lag2'] = data['close'].shift(2)\n",
    "\n",
    "    \n",
    "    # Add Daily Returns and Log Returns\n",
    "    df['Daily_Return'] = df['close'].pct_change()\n",
    "    df['Log_Return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # date is as index    \n",
    "    data.set_index('date', inplace=True)\n",
    "    \n",
    "\n",
    "    # Assuming your data is loaded in the DataFrame 'data'\n",
    "    # Ensure the date column is in datetime format and set it as index\n",
    "    \n",
    "    \n",
    "    # Assuming 'data' is your DataFrame and 'date' is the index\n",
    "    # Ensure the 'close' column is properly formatted as numeric\n",
    "    data['close'] = pd.to_numeric(data['close'], errors='coerce')\n",
    "    \n",
    "    # Fill any NaN values that may appear (using .ffill)\n",
    "    data['close'] = data['close'].ffill()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Calculate MACD using pandas_ta\n",
    "    macd_result = ta.macd(data['close'], fast=12, slow=26, signal=9)\n",
    "    \n",
    "    # Add MACD components to the data\n",
    "    data['MACD'] = macd_result['MACD_12_26_9']\n",
    "    data['MACD_signal'] = macd_result['MACDs_12_26_9']\n",
    "    data['MACD_hist'] = macd_result['MACDh_12_26_9']\n",
    "    \n",
    "    # 2. Calculate RSI (Relative Strength Index)\n",
    "    data['RSI'] = ta.rsi(data['close'], length=14)\n",
    "    \n",
    "    # Step 2: Recalculate VWAP after setting 'date' as the index\n",
    "    data['VWAP'] = ta.vwap(high=data['high'], low=data['low'], close=data['close'], volume=data['volume'])\n",
    "    \n",
    "    # Calculate Bollinger Bands (returns a DataFrame, not individual series)\n",
    "    bbands = ta.bbands(data['close'], length=20, std=2)\n",
    "    \n",
    "    \n",
    "    # Extract the individual bands from the result\n",
    "    data['BB_upper'] = bbands['BBL_20_2.0']\n",
    "    data['BB_middle'] = bbands['BBM_20_2.0']\n",
    "    data['BB_lower'] = bbands['BBU_20_2.0']\n",
    "\n",
    "    \n",
    "    # 4. Calculate On-Balance Volume (OBV)\n",
    "    data['OBV'] = ta.obv(data['close'], data['volume'])\n",
    "\n",
    "    \n",
    "    # Default parameters for AF (Acceleration Factor) are 0.02 and maximum AF is 0.2\n",
    "    # Calculate Parabolic SAR\n",
    "    # pandas_ta.psar returns multiple columns: `PSARl_0.02_0.2`, `PSARs_0.02_0.2`, and `PSAR_0.02_0.2`\n",
    "    psar = ta.psar(data['high'], data['low'], data['close'], step=0.02, max_step=0.2)\n",
    "\n",
    "    \n",
    "    # Combine PSARl and PSARs into a single column\n",
    "    data['PSAR'] = psar['PSARl_0.02_0.2'].combine_first(psar['PSARs_0.02_0.2'])\n",
    "\n",
    "\n",
    "    # 5. Calculate ATR (Average True Range)\n",
    "    data['ATR'] = ta.atr(data['high'], data['low'], data['close'], length=14)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # Calculate Ichimoku Cloud\n",
    "    ichimoku = ta.ichimoku(data['high'], data['low'], data['close'], window1=9, window2=26, window3=52)\n",
    "    # Extract Ichimoku components\n",
    "    data['Tenkan-sen'] = ichimoku[0]['ITS_9']  # Conversion Line\n",
    "    data['Kijun-sen'] = ichimoku[0]['IKS_26']  # Base Line\n",
    "    data['Chikou Span'] = ichimoku[0]['ICS_26']  # Lagging Span\n",
    "\n",
    "        \n",
    "\n",
    "    # Calculate CCI Commodity Channel Index (CCI) \n",
    "    data['CCI'] = ta.cci(data['high'], data['low'], data['close'], length=20)\n",
    "\n",
    "\n",
    "\n",
    "    # Reset index to make 'date' a regular column\n",
    "    data = data.reset_index()\n",
    "\n",
    "\n",
    "    # data=data_reset.dropna() \n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    new_file=f'technical indicators/{ticker}_indicators.csv'\n",
    "    data.to_csv(new_file, index=False)\n",
    "    print(f\"TCS data saved to {new_file}\")\n",
    "    return data\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4276290f-f11b-4fd2-a74d-d49b4732e28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCS data saved to technical indicators/TCS.NS_indicators.csv\n"
     ]
    }
   ],
   "source": [
    "data=technical_generator(\"TCS.NS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "637026c4-fdf5-46af-ba42-db658680bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "\n",
    "def get_directory(base_dir, data_type):\n",
    "    \"\"\"Returns the correct directory path for storing data.\"\"\"\n",
    "    if data_type not in ['train', 'test']:\n",
    "        raise ValueError(\"Invalid data_type. Choose 'train' or 'test'\")\n",
    "    \n",
    "    raw_data_dir = os.path.join(base_dir, data_type, 'raw_data')\n",
    "    tech_data_dir = os.path.join(base_dir, data_type, 'technical_indicators')\n",
    "    os.makedirs(raw_data_dir, exist_ok=True)\n",
    "    os.makedirs(tech_data_dir, exist_ok=True)\n",
    "    \n",
    "    return raw_data_dir, tech_data_dir\n",
    "\n",
    "def download_historic_data(ticker, data_type='train', base_dir='data'):\n",
    "    \"\"\"Downloads historical stock data and saves it to the appropriate directory.\"\"\"\n",
    "    raw_data_dir, _ = get_directory(base_dir, data_type)\n",
    "    csv_file = os.path.join(raw_data_dir, f'{ticker}_data.csv')\n",
    "    \n",
    "    data = yf.download(ticker, start=\"2023-12-01\", end=\"2025-02-21\")\n",
    "    data.reset_index(inplace=True)\n",
    "    \n",
    "    data = data.rename(columns={'Date': 'date', 'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close', 'Volume': 'volume'})\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    \n",
    "    data.to_csv(csv_file, index=False)\n",
    "    del_second_row(csv_file)\n",
    "    print(f\"Data saved to {csv_file}\")\n",
    "\n",
    "def del_second_row(file_path):\n",
    "    \"\"\"Removes the second row from a CSV file.\"\"\"\n",
    "    import csv\n",
    "    with open(file_path, \"r\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        rows = list(csv.reader(file))\n",
    "    if len(rows) > 1:\n",
    "        rows.pop(1)\n",
    "    with open(file_path, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        csv.writer(file).writerows(rows)\n",
    "\n",
    "def generate_technical_indicators(ticker, data_type='train', base_dir='data'):\n",
    "    \"\"\"Loads raw stock data, computes technical indicators, and saves it.\"\"\"\n",
    "    raw_data_dir, tech_data_dir = get_directory(base_dir, data_type)\n",
    "    \n",
    "    file_path = os.path.join(raw_data_dir, f'{ticker}_data.csv')\n",
    "    new_file = os.path.join(tech_data_dir, f'{ticker}_indicators.csv')\n",
    "\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['year'] = data['date'].dt.year\n",
    "    data['month'] = data['date'].dt.month\n",
    "    data['day'] = data['date'].dt.day\n",
    "    data['dayofweek'] = data['date'].dt.dayofweek\n",
    "    data['quarter'] = data['date'].dt.quarter\n",
    "    data['dayofyear'] = data['date'].dt.dayofyear\n",
    "\n",
    "    # Add Simple Moving Averages (SMA)\n",
    "    data['SMA_5'] = ta.sma(data['close'], length=5)\n",
    "    data['SMA_8'] = ta.sma(data['close'], length=8)\n",
    "    data['SMA_13'] = ta.sma(data['close'], length=13)\n",
    "    data['SMA_21'] = ta.sma(data['close'], length=21)\n",
    "    data['SMA_50'] = ta.sma(data['close'], length=50)\n",
    "   \n",
    "    # Add Exponential Moving Averages (EMA)\n",
    "    data['EMA_5'] = ta.ema(data['close'], length=5)\n",
    "    data['EMA_8'] = ta.ema(data['close'], length=8)\n",
    "    data['EMA_13'] = ta.ema(data['close'], length=13)\n",
    "    data['EMA_21'] = ta.ema(data['close'], length=21)\n",
    "    data['EMA_50'] = ta.ema(data['close'], length=50)\n",
    " \n",
    "    # Add Stochastic Oscillator (%K and %D)\n",
    "    stoch = ta.stoch(data['high'], data['low'], data['close'], k=14, d=3)\n",
    "    data['Stoch_%K'] = stoch['STOCHk_14_3_3']\n",
    "    data['Stoch_%D'] = stoch['STOCHd_14_3_3']\n",
    "    \n",
    "    # Add Average Directional Index (ADX)\n",
    "    data['ADX'] = ta.adx(data['high'], data['low'], data['close'], length=14)['ADX_14']\n",
    "\n",
    "    # Add Lag Features\n",
    "    data['Close_lag1'] = data['close'].shift(1)\n",
    "    data['close_lag2'] = data['close'].shift(2)\n",
    "    \n",
    "    # Add Daily Returns\n",
    "    data['Daily_Return'] = data['close'].pct_change()\n",
    "\n",
    "    # date is as index    \n",
    "    data.set_index('date', inplace=True)\n",
    "     \n",
    "    data['close'] = pd.to_numeric(data['close'], errors='coerce')  # Convert to float\n",
    "    data['close'].fillna(method='ffill', inplace=True)  # Fill missing values\n",
    "\n",
    "    \n",
    "    # Calculate MACD using pandas_ta\n",
    "    macd_result = ta.macd(data['close'], fast=12, slow=26, signal=9)\n",
    "    \n",
    "    # Add MACD components to the data\n",
    "    data['MACD'] = macd_result['MACD_12_26_9']\n",
    "    data['MACD_signal'] = macd_result['MACDs_12_26_9']\n",
    "    data['MACD_hist'] = macd_result['MACDh_12_26_9']\n",
    "    \n",
    "    # 2. Calculate RSI (Relative Strength Index)\n",
    "    data['RSI'] = ta.rsi(data['close'], length=14)\n",
    "    \n",
    "    # Step 2: Recalculate VWAP after setting 'date' as the index\n",
    "    data['VWAP'] = ta.vwap(high=data['high'], low=data['low'], close=data['close'], volume=data['volume'])\n",
    "    \n",
    "    # # Calculate Bollinger Bands (returns a DataFrame, not individual series)\n",
    "    # bbands = ta.bbands(data['close'], length=20, std=2)\n",
    "     \n",
    "    # # Extract the individual bands from the result\n",
    "    # data['BB_upper'] = bbands['BBL_20_2.0']\n",
    "    # data['BB_middle'] = bbands['BBM_20_2.0']\n",
    "    # data['BB_lower'] = bbands['BBU_20_2.0']\n",
    "    data['BB_upper'], data['BB_middle'], data['BB_lower'] = ta.bbands(data['close'], length=20)[['BBU_20_2.0', 'BBM_20_2.0', 'BBL_20_2.0']].T.values\n",
    "\n",
    "    # 4. Calculate On-Balance Volume (OBV)\n",
    "    data['OBV'] = ta.obv(data['close'], data['volume'])\n",
    "\n",
    "    # Default parameters for AF (Acceleration Factor) are 0.02 and maximum AF is 0.2\n",
    "    # Calculate Parabolic SAR\n",
    "    # pandas_ta.psar returns multiple columns: `PSARl_0.02_0.2`, `PSARs_0.02_0.2`, and `PSAR_0.02_0.2`\n",
    "    psar = ta.psar(data['high'], data['low'], data['close'], step=0.02, max_step=0.2)\n",
    "\n",
    "    # Combine PSARl and PSARs into a single column\n",
    "    data['PSAR'] = psar['PSARl_0.02_0.2'].combine_first(psar['PSARs_0.02_0.2'])\n",
    "\n",
    "    # 5. Calculate ATR (Average True Range)\n",
    "    data['ATR'] = ta.atr(data['high'], data['low'], data['close'], length=14)\n",
    "\n",
    "    # Calculate Ichimoku Cloud\n",
    "    ichimoku = ta.ichimoku(data['high'], data['low'], data['close'], window1=9, window2=26, window3=52)\n",
    "    # Extract Ichimoku components\n",
    "    data['Tenkan-sen'] = ichimoku[0]['ITS_9']  # Conversion Line\n",
    "    data['Kijun-sen'] = ichimoku[0]['IKS_26']  # Base Line\n",
    "    data['Chikou Span'] = ichimoku[0]['ICS_26']  # Lagging Span\n",
    "\n",
    "    # Calculate CCI Commodity Channel Index (CCI) \n",
    "    data['CCI'] = ta.cci(data['high'], data['low'], data['close'], length=20)\n",
    "\n",
    "    # Reset index to make 'date' a regular column\n",
    "    data = data.reset_index()\n",
    "\n",
    "    data.to_csv(new_file, index=False)\n",
    "    print(f\"Technical indicators saved to {new_file}\")\n",
    "    # return data\n",
    "\n",
    "# Example Usage:\n",
    "# download_historic_data('AAPL', data_type='test')\n",
    "# generate_technical_indicators('AAPL', data_type='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7847e3c5-cde0-40c6-9d0a-5d1944feaa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def git_commit():\n",
    "    from os import system\n",
    "        # Push changes using git\n",
    "    repo_dir = os.getcwd() \n",
    "    system(f\"cd {repo_dir} && git add .\")\n",
    "    system(f'cd {repo_dir} && git commit -m \"Commited via Python\"')\n",
    "    system(f\"cd {repo_dir} && git push origin main\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ee1f6fb-f4b7-4cbb-8c33-c7afa38ae196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['TCS.NS']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data\\test\\raw_data\\TCS.NS_data.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m download_historic_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTCS.NS\u001b[39m\u001b[38;5;124m'\u001b[39m, data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m generate_technical_indicators(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTCS.NS\u001b[39m\u001b[38;5;124m'\u001b[39m, data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 77\u001b[0m, in \u001b[0;36mgenerate_technical_indicators\u001b[1;34m(ticker, data_type, base_dir)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Add Stochastic Oscillator (%K and %D)\u001b[39;00m\n\u001b[0;32m     76\u001b[0m stoch \u001b[38;5;241m=\u001b[39m ta\u001b[38;5;241m.\u001b[39mstoch(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m], k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m, d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStoch_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m stoch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTOCHk_14_3_3\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     78\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStoch_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m stoch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTOCHd_14_3_3\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Add Average Directional Index (ADX)\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "download_historic_data('TCS.NS', data_type='test')\n",
    "generate_technical_indicators('TCS.NS', data_type='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71a7ac5d-cb86-426e-8061-8f490d79a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79cc11e5-e6c6-4449-9cf6-371555ed0a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['MRF.NS']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    }
   ],
   "source": [
    "data = yf.download(\"MRF.NS\", start=\"2023-12-01\", end=\"2025-02-21\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f29adfd-c3d8-4d6d-8188-a9df18346b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.Ticker(\"TCS.NS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fddda5fd-b5a1-43a9-a094-146cc5f3c855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TCS.NS: possibly delisted; no price data found  (period=1d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "stock = yf.Ticker(\"TCS.NS\")\n",
    "df = stock.history(period=\"1d\")  # Adjust period as needed\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53463e84-1e63-48b0-8062-aeb55cd991d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in d:\\program_files\\anaconda\\lib\\site-packages (0.2.51)\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.54-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in d:\\program_files\\anaconda\\lib\\site-packages (from yfinance) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in d:\\program_files\\anaconda\\lib\\site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in d:\\program_files\\anaconda\\lib\\site-packages (from yfinance) (2.32.2)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in d:\\program_files\\anaconda\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in d:\\program_files\\anaconda\\lib\\site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in d:\\program_files\\anaconda\\lib\\site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in d:\\program_files\\anaconda\\lib\\site-packages (from yfinance) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in d:\\program_files\\anaconda\\lib\\site-packages (from yfinance) (3.17.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in d:\\program_files\\anaconda\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\program_files\\anaconda\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\program_files\\anaconda\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\program_files\\anaconda\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\program_files\\anaconda\\lib\\site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\program_files\\anaconda\\lib\\site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\program_files\\anaconda\\lib\\site-packages (from requests>=2.31->yfinance) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\program_files\\anaconda\\lib\\site-packages (from requests>=2.31->yfinance) (2024.12.14)\n",
      "Requirement already satisfied: six>=1.5 in d:\\program_files\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\n",
      "Downloading yfinance-0.2.54-py2.py3-none-any.whl (108 kB)\n",
      "   ---------------------------------------- 0.0/108.7 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/108.7 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/108.7 kB ? eta -:--:--\n",
      "   ----------- --------------------------- 30.7/108.7 kB 217.9 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 30.7/108.7 kB 217.9 kB/s eta 0:00:01\n",
      "   ------------------------- ------------- 71.7/108.7 kB 280.5 kB/s eta 0:00:01\n",
      "   ------------------------- ------------- 71.7/108.7 kB 280.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 108.7/108.7 kB 314.6 kB/s eta 0:00:00\n",
      "Installing collected packages: yfinance\n",
      "  Attempting uninstall: yfinance\n",
      "    Found existing installation: yfinance 0.2.51\n",
      "    Uninstalling yfinance-0.2.51:\n",
      "      Successfully uninstalled yfinance-0.2.51\n",
      "Successfully installed yfinance-0.2.54\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f85a8377-7eaa-4c70-995d-29ab485dc3be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_datareader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_datareader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data \u001b[38;5;28;01mas\u001b[39;00m pdr\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m yf\u001b[38;5;241m.\u001b[39mpdr_override()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas_datareader'"
     ]
    }
   ],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "\n",
    "yf.pdr_override()\n",
    "\n",
    "try:\n",
    "    df = pdr.get_data_yahoo(\"TCS.NS\", period=\"1d\")\n",
    "    print(df)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2426192d-9169-443d-9db5-c892c8f9b051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
