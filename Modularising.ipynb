{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68479312-fb5e-47ae-a4a6-839996a4a47c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_ta as ta\n",
    "\n",
    "def load_data(url):\n",
    "    \"\"\"Load dataset from a URL.\"\"\"\n",
    "    data = pd.read_csv(url)\n",
    "    return data\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"Preprocess data by selecting features, adding indicators, and normalizing.\"\"\"\n",
    "    selected_features = ['close', 'high', 'low', 'open', 'volume', 'MACD', 'RSI', 'ATR', 'BB_upper', 'BB_middle', 'BB_lower']\n",
    "    data['SMA_10'] = data['close'].rolling(window=10).mean()\n",
    "    data['SMA_21'] = data['close'].rolling(window=21).mean()\n",
    "    data['EMA_5'] = ta.ema(data['close'], length=5)\n",
    "    data['EMA_8'] = ta.ema(data['close'], length=8)\n",
    "    data['EMA_13'] = ta.ema(data['close'], length=13)\n",
    "    data = data[selected_features].dropna()\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    return scaled_data, scaler\n",
    "\n",
    "def create_sequences(data, sequence_length=45):\n",
    "    \"\"\"Create sequences for model training.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length - 1):\n",
    "        X.append(data[i:i + sequence_length])\n",
    "        y.append(data[i + sequence_length, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def split_data(X, y, train_ratio=0.7, val_ratio=0.15):\n",
    "    \"\"\"Split data into training, validation, and test sets.\"\"\"\n",
    "    train_size = int(len(X) * train_ratio)\n",
    "    val_size = int(len(X) * val_ratio)\n",
    "    return (X[:train_size], y[:train_size],\n",
    "            X[train_size:train_size+val_size], y[train_size:train_size+val_size],\n",
    "            X[train_size+val_size:], y[train_size+val_size:])\n",
    "\n",
    "def build_model(input_shape):\n",
    "    \"\"\"Build a Bidirectional GRU model.\"\"\"\n",
    "    model = Sequential([\n",
    "        Bidirectional(GRU(256, return_sequences=True, input_shape=input_shape)),\n",
    "        Dropout(0.18),\n",
    "        Bidirectional(GRU(512, return_sequences=False)),\n",
    "        Dropout(0.18),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    optimizer = AdamW(learning_rate=0.0005)\n",
    "    model.compile(optimizer=optimizer, loss=Huber(delta=1.0))\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=70, batch_size=24):\n",
    "    \"\"\"Train the model with early stopping and learning rate reduction.\"\"\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "    ]\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                        validation_data=(X_val, y_val), callbacks=callbacks)\n",
    "    return history\n",
    "\n",
    "def load_trained_model(model_path):\n",
    "    \"\"\"Load a trained model from file.\"\"\"\n",
    "    return load_model(model_path)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, scaler, X_test_shape):\n",
    "    \"\"\"Evaluate the model and calculate performance metrics.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_actual = scaler.inverse_transform(np.concatenate((y_pred, np.zeros((y_pred.shape[0], X_test_shape[2] - 1))), axis=1))[:, 0]\n",
    "    y_test_actual = scaler.inverse_transform(np.concatenate((y_test.reshape(-1, 1), np.zeros((y_test.shape[0], X_test_shape[2] - 1))), axis=1))[:, 0]\n",
    "    \n",
    "    metrics = {\n",
    "        'MAE': mean_absolute_error(y_test_actual, y_pred_actual),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test_actual, y_pred_actual)),\n",
    "        'MAPE': mean_absolute_percentage_error(y_test_actual, y_pred_actual) * 100,\n",
    "        'RÂ²': r2_score(y_test_actual, y_pred_actual),\n",
    "        'RMSE %': (np.sqrt(mean_squared_error(y_test_actual, y_pred_actual)) / np.mean(y_test_actual)) * 100\n",
    "    }\n",
    "    return metrics, y_test_actual, y_pred_actual\n",
    "\n",
    "def plot_predictions(y_test_actual, y_pred_actual):\n",
    "    \"\"\"Plot actual vs predicted stock prices.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_test_actual, label='Actual')\n",
    "    plt.plot(y_pred_actual, label='Predicted')\n",
    "    plt.title('Next-Day Stock Price Prediction (GRU)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Stock Price')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00798a90-d15c-40b1-927b-5144031a8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow():\n",
    "    # Execution\n",
    "    url = \"https://raw.githubusercontent.com/ranjithkumar5807/stock-prediction/refs/heads/main/data/test/technical_indicators/TCS.NS_indicators.csv\"\n",
    "    model_path=\"https://github.com/ranjithkumar5807/stock-prediction/blob/ddbf3c73929026e3405acdcbb0dbe8876d723bb4/Model/TCS_mae%2047rmse63%20r2%2097%20mape1.36.keras\"\n",
    "    data = load_data(url)\n",
    "    scaled_data, scaler = preprocess_data(data)\n",
    "    X, y = create_sequences(scaled_data)\n",
    "    # X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y)\n",
    "    # model = build_model((X_train.shape[1], X_train.shape[2]))\n",
    "    # history = train_model(model, X_train, y_train, X_val, y_val)\n",
    "    model=load_trained_model(model_path)\n",
    "    # metrics, y_test_actual, y_pred_actual = evaluate_model(model, X_test, y_test, scaler, X_test.shape)\n",
    "    metrics, y_test_actual, y_pred_actual = evaluate_model(model, X, y, scaler, X.shape)\n",
    "    \n",
    "    plot_predictions(y_test_actual, y_pred_actual)\n",
    "    \n",
    "    # Print Evaluation Metrics\n",
    "    for key, value in metrics.items():\n",
    "        print(f'{key}: {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f60fab6-9c6c-41e8-85c1-1db32d8e835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce83ee-fa1c-4d43-b88e-8e6c58d4277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc9f794-09ce-4cb7-ac5c-15a168b9cce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
